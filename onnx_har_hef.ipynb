{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmqQb4cRh0ojdJrb1FswPY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcory-hub/hailo-colab/blob/main/onnx_har_hef.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From onnx via har to hef\n",
        "\n",
        "Goal of this notebook is to make a `HEF` file is the file that runs on the `hailo-8l` device that is on the AI-kit. For a schematic overview and more details check the hailo docs about the [model build process](https://hailo.ai/developer-zone/documentation/dataflow-compiler-v3-29-0/?sp_referrer=overview/overview.html).\n",
        "\n",
        "Credits to trieut415! A lot of the code from hailo is adjusted inspired on his [post](https://community.hailo.ai/t/guide-to-using-the-dfc-to-convert-a-modified-yolov11-on-google-colab/7131/3) in the hailo community. Especially the solution to run the Dataflow Compiler in a virtual environment solved my initial problem. Furthermore, the codeblock to make the calibration data is more robust."
      ],
      "metadata": {
        "id": "i1hxKMSZkP_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "### 1. Parsing from onnx to har:\n",
        "- Input: onnx file\n",
        "- Output: har file (model representation and parameters (32-bits weights))\n",
        "\n",
        "### 2. Model Optimization:\n",
        "- input: har file (32-bits) and calibration images\n",
        "- output: har file (optimized model representation and parameters (quantized weights))\n",
        "\n",
        "  Conversion of the har file with float32 parameters to integers. To convert te parameters tun the model emulation in native mode on a small set of images (not annotated).\n",
        "\n",
        "  #### Substeps\n",
        "\n",
        "  1. Prepare callibration set\n",
        "  2. Load har file (32-bits) from model conversion\n",
        "  3. Create model script\n",
        "\n",
        "\n",
        "### 3. Model Compilation:\n",
        "- input: har (optimized)\n",
        "- output: hef\n",
        "\n",
        "  The quantized model is compiled into a specific binary format called HEF (Hailo Executable Format). This format is optimized for the Hailo device's architecture and allows for efficient execution of the model's operations."
      ],
      "metadata": {
        "id": "1kVVRWr9TprW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before your start\n",
        "1. Download hailo dataflow compiler  from https://hailo.ai/developer-zone/software-downloads/ (you need to make an account) and upload it to your Google Drive. To check the python version of Colab you can run the command below.\n",
        "2. Collect a set of 1024 images needed for callibration. These images need no annotation, but should be representatieve. Zip it preferably with the name calibrationDataset.zip (On mac use `ditto -c -k --norsrc --keepParent calibrationDataset calibrationDataset.zip`)\n",
        "3. Spin up a Colab with GPU, needed for the optimization step."
      ],
      "metadata": {
        "id": "eJWdt-dboiFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "Xs5P5fxEpbnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dataflow Compiler (DFC) in virtual environment (venv)"
      ],
      "metadata": {
        "id": "8iAAzfrJajBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "SUPnZCbI96Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make virual environment\n",
        "\n",
        "# Update and install packages needed for DFC\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y python3-dev python3-distutils python3-tk libfuse2 graphviz libgraphviz-dev\n",
        "\n",
        "# Will need a venv to install the DFC in\n",
        "!pip install --upgrade pip virtualenv\n",
        "!virtualenv my_env"
      ],
      "metadata": {
        "id": "XNtqRTnpJm2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the next codeblock, make sure you downloaded hailo dataflow compiler (python 3.10) from https://hailo.ai/developer-zone/software-downloads/ and copied the .whl to your Google Drive. Change the filename if their is an update i missed.\n"
      ],
      "metadata": {
        "id": "LwsOA_V3I4zW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing the Dataflow Compiler, update the filename if needed\n",
        "!my_env/bin/pip install /content/gdrive/MyDrive/hailo_dataflow_compiler-3.29.0-py3-none-linux_x86_64.whl\n",
        "\n",
        "# Check the version and show help information\n",
        "!my_env/bin/hailo --version\n",
        "!my_env/bin/hailo -h"
      ],
      "metadata": {
        "id": "p71hAN7HJf7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.  Parsing from onnx --> har\n",
        "\n",
        "1. Select the hardware architecture. For the raspberry AI-kits it is `hailo8l`.\n",
        "2. Open the [netron](https://netron.app/) site, Click `Open Model` and select your onnx file on your local computer.\n",
        "3. To identify the end nodes, they are the nodes right before the post-processing operations at the very bottom of the model. Their are 2 end nodes per map. I used a search for `onnx::Reshape` to get to the two `conv` layers that pointed to the `onnx::Reshape`.\n",
        "\n",
        "  In an unmodified yolov8 till yolo11 model this are the endpoints:\n",
        "  ```\n",
        "\"/model.23/cv2.2/cv2.2.2/Conv\",\n",
        "\"/model.23/cv3.2/cv3.2.2/Conv\",\n",
        "\"/model.23/cv2.1/cv2.1.2/Conv\",\n",
        "\"/model.23/cv3.1/cv3.1.2/Conv\",\n",
        "\"/model.23/cv2.0/cv2.0.2/Conv\",\n",
        "\"/model.23/cv3.0/cv3.0.2/Conv\",\n",
        "```\n",
        "  If they are different, then depicted above you have to change it in the code block below.\n",
        "4. Check the net_input_shapes in netron. Adjust it if your \"input layer name\": [batch, rgb, image size] are different from:\n",
        "  ```\n",
        "  \"images\": [1, 3, 320, 320]\n",
        "  ```\n",
        "\n",
        "5. Run the codeblocks below. The har file is created by the command `runner.translate_onnx_model` and saved with `runner.save_har`. To use the DFC in the venv we make and save the python code in the first codeblock and run it in the venv in the second codeblock. More details about the conversion can be found in the [Parsing tutorial](https://hailo.ai/developer-zone/documentation/dataflow-compiler-v3-29-0/?sp_referrer=tutorials_notebooks/notebooks/DFC_1_Parsing_Tutorial.html)."
      ],
      "metadata": {
        "id": "euWouzZiKcEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"translate_model.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "\n",
        "from hailo_sdk_client import ClientRunner\n",
        "\n",
        "# Set hailo hardware architecture and onnx model and model path\n",
        "chosen_hw_arch = \"hailo8l\" # @param [\"hailo8l\", \"hailo8\", \"hailo8r\", \"hailo10h\", \"hailo15h\", \"hailo15m\"]\n",
        "onnx_model_name = \"best_opset9\" # @param {type:\"string\"}\n",
        "onnx_path = \"/content/gdrive/MyDrive/best_opset9.onnx\" # @param {type:\"string\"}\n",
        "\n",
        "print(\"Starting model translation...\")\n",
        "\n",
        "# Initialize the ClientRunner\n",
        "runner = ClientRunner(hw_arch=chosen_hw_arch)\n",
        "\n",
        "# Change the end_node_names if netron show different end nodes\n",
        "end_node_names = [\n",
        "  \"/model.23/cv2.0/cv2.0.2/Conv\",\n",
        "  \"/model.23/cv3.0/cv3.0.2/Conv\",\n",
        "  \"/model.23/cv2.1/cv2.1.2/Conv\",\n",
        "  \"/model.23/cv3.1/cv3.1.2/Conv\",\n",
        "  \"/model.23/cv2.2/cv2.2.2/Conv\",\n",
        "  \"/model.23/cv3.2/cv3.2.2/Conv\",\n",
        "]\n",
        "\n",
        "try:\n",
        "    # Translate the onnx model to har file\n",
        "    hn, npz = runner.translate_onnx_model(\n",
        "        onnx_path,\n",
        "        onnx_model_name,\n",
        "        end_node_names=end_node_names,\n",
        "        net_input_shapes={\"images\": [1, 3, 320, 320]},  # Adjust input shapes if needed\n",
        "    )\n",
        "    print(\"Model translation successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during model translation: {e}\")\n",
        "    raise\n",
        "\n",
        "# Save the har file\n",
        "hailo_model_har_name = f\"{onnx_model_name}_hailo_model.har\"\n",
        "try:\n",
        "    runner.save_har(hailo_model_har_name)\n",
        "    print(f\"HAR file saved as: {hailo_model_har_name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving HAR file: {e}\")\n",
        "\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "8_VrxC1pIsv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run model in CLI\n",
        "!my_env/bin/python translate_model.py"
      ],
      "metadata": {
        "id": "gidGCc-wLf1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Model optimization\n",
        "The optimazation from Hailo replaced by the optimization in the guide from trieut415.\n",
        "\n",
        "1. Print dictionary of layers and operations\n",
        "2. Load har\n",
        "3. create model script\n"
      ],
      "metadata": {
        "id": "CR5d4kdrLlJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Print layers"
      ],
      "metadata": {
        "id": "gVkx9ZdKwmkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"inspect_layers.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "\n",
        "from hailo_sdk_client import ClientRunner\n",
        "\n",
        "# Load the HAR file\n",
        "har_path = \"/content/best_opset9_hailo_model.har\" # @param {type:\"string\"}\n",
        "\n",
        "runner = ClientRunner(har=har_path)\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "try:\n",
        "    # Access the HailoNet as an OrderedDict\n",
        "    hn_dict = runner.get_hn()  # Or use runner._hn if get_hn() is unavailable\n",
        "    print(\"Inspecting layers from HailoNet (OrderedDict):\")\n",
        "\n",
        "    # Pretty-print each layer\n",
        "    for key, value in hn_dict.items():\n",
        "        print(f\"Key: {key}\")\n",
        "        pprint(value)\n",
        "        print(\"\\\\n\" + \"=\"*80 + \"\\\\n\")  # Add a separator between layers for clarity\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error while inspecting hn_dict: {e}\")\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "pyfvCJe7x3wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run model in CLI\n",
        "!my_env/bin/python inspect_layers.py"
      ],
      "metadata": {
        "id": "8Iktg68-3Dmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the top of the output the output_layers_order is printed. It should look like this. The renamed layers we need to check in de codeblock below and adjust if needed.\n",
        "\n",
        "```\n",
        "================================================================================\n",
        "\n",
        "Key: net_params\n",
        "OrderedDict([('version', '1.0'),\n",
        "             ('stage', 'HN'),\n",
        "             ('clusters_placement', [[]]),\n",
        "             ('clusters_to_skip', []),\n",
        "             ('output_layers_order',\n",
        "              ['best_opset9/conv51',\n",
        "               'best_opset9/conv54',\n",
        "               'best_opset9/conv62',\n",
        "               'best_opset9/conv65',\n",
        "               'best_opset9/conv77',\n",
        "               'best_opset9/conv80']),\n",
        "             ('transposed_net', False),\n",
        "             ('net_scopes', ['best_opset9'])])\n",
        "\n",
        "================================================================================\n",
        "```"
      ],
      "metadata": {
        "id": "ITlcUUSC7K9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check it the output layers have the correct name in the code in the next codeblock. Adjust if needed."
      ],
      "metadata": {
        "id": "Vj2BYp9cDGxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Updated NMS layer configuration dictionary\n",
        "nms_layer_config = {\n",
        "    \"nms_scores_th\": 0.3,\n",
        "    \"nms_iou_th\": 0.7,\n",
        "    \"image_dims\": [640, 640],\n",
        "    \"max_proposals_per_class\": 25,\n",
        "    \"classes\": 1,\n",
        "    \"regression_length\": 16,\n",
        "    \"background_removal\": False,\n",
        "    \"background_removal_index\": 0,\n",
        "    \"bbox_decoders\": [\n",
        "        {\n",
        "            \"name\": \"bbox_decoder51\", # Change the number (51) to the number of the reg_layer\n",
        "            \"stride\": 16,\n",
        "            \"reg_layer\": \"conv51\",    # CHECK THIS\n",
        "            \"cls_layer\": \"conv54\"     # CHECK THIS\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"bbox_decoder62\", # Change the number (62) to the number of the reg_layer\n",
        "            \"stride\": 32,\n",
        "            \"reg_layer\": \"conv62\",    # CHECK THIS\n",
        "            \"cls_layer\": \"conv65\"     # CHECK THIS\n",
        "        }\n",
        "        {\n",
        "            \"name\": \"bbox_decoder77\", # Change the number (62) to the number of the reg_layer\n",
        "            \"stride\": 32,\n",
        "            \"reg_layer\": \"conv77\",    # CHECK THIS\n",
        "            \"cls_layer\": \"conv80\"     # CHECK THIS\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Path to save the updated JSON configuration\n",
        "output_dir = \"/save/path/\"\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "output_path = os.path.join(output_dir, \"nms_layer_config.json\")\n",
        "\n",
        "# Save the updated configuration as a JSON file\n",
        "with open(output_path, \"w\") as json_file:\n",
        "    json.dump(nms_layer_config, json_file, indent=4)\n",
        "\n",
        "print(f\"NMS layer configuration saved to {output_path}\")"
      ],
      "metadata": {
        "id": "ZKSdmDLf8RUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Calibration data\n",
        "\n",
        "\n",
        "- The dataset should contain at least 1024 representative images (not labeled).\n",
        "- Use a GPU."
      ],
      "metadata": {
        "id": "zcgJDdLZMEby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Unzip the calibration dataset and rename the folder if needed."
      ],
      "metadata": {
        "id": "xuHkgWfYP50Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Define Paths with Parameters\n",
        "calibrationset_path = \"/content/gdrive/MyDrive/calibrationDataset.zip\"\n",
        "calibrationset_filename = \"calibrationDataset\"\n",
        "\n",
        "try:\n",
        "  # Unzip the Dataset\n",
        "  !unzip {calibrationset_path} -d '/content/'\n",
        "\n",
        "  # Rename the Extracted Folder\n",
        "  old_path = f'/content/{calibrationset_filename}'\n",
        "  new_path = '/content/calibrationDataset'\n",
        "  if os.path.exists(old_path):\n",
        "    os.rename(old_path, new_path)\n",
        "  else:\n",
        "    print(f\"Error: {old_path} does not exist.\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "F29cF26uNl2L",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Make calibration data. Adjust the size of the image if you input layer has an other format (often it is 640x640)."
      ],
      "metadata": {
        "id": "JGIYnr5PQOs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make calibration data for the optimization step\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# Paths to directories and files\n",
        "image_dir = '/content/calibrationDataset'\n",
        "output_dir = '/content/output_dir'\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# File paths for saving calibration data\n",
        "calibration_data_path = os.path.join(output_dir, \"calibration_data.npy\")\n",
        "processed_data_path = os.path.join(output_dir, \"processed_calibration_data.npy\")\n",
        "\n",
        "# Initialize an empty list for calibration data\n",
        "calib_data = []\n",
        "\n",
        "# Process all image files in the directory\n",
        "for img_name in os.listdir(image_dir):\n",
        "    img_path = os.path.join(image_dir, img_name)\n",
        "    if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img = Image.open(img_path).resize((320, 320))  # Resize to desired dimensions\n",
        "        img_array = np.array(img) / 255.0  # Normalize to [0, 1]\n",
        "        calib_data.append(img_array)\n",
        "\n",
        "# Convert the calibration data to a NumPy array\n",
        "calib_data = np.array(calib_data)\n",
        "\n",
        "# Save the normalized calibration data\n",
        "np.save(calibration_data_path, calib_data)\n",
        "print(f\"Normalized calibration dataset saved with shape: {calib_data.shape} to {calibration_data_path}\")\n",
        "\n",
        "# Scale the normalized data back to [0, 255]\n",
        "processed_calibration_data = calib_data * 255.0\n",
        "\n",
        "# Save the processed calibration data\n",
        "np.save(processed_data_path, processed_calibration_data)\n",
        "print(f\"Processed calibration dataset saved with shape: {processed_calibration_data.shape} to {processed_data_path}\")\n",
        "\n",
        "# Stop and start runtime after this codeblock!\n",
        "# even after processing, the calib_data array might still be in memory."
      ],
      "metadata": {
        "id": "ifbGGXLdMFsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STOP- AND RESTART SESSION: After running the previous codeblock stop and restart the session to clear the memory!"
      ],
      "metadata": {
        "id": "_PqR9-yRZrEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO check if this code gives the same output, should not keep data in memory"
      ],
      "metadata": {
        "id": "pJWwm96ifi3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Verbeterde code nog checken en vergelijken met output van bovenstaande\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Paths to directories and files\n",
        "image_dir = '/content/dataset/valid/images'\n",
        "output_dir = '/content/output_dir'\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# File paths for saving processed data\n",
        "calibration_data_path = os.path.join(output_dir, \"calibration_data.npy\")\n",
        "processed_data_path = os.path.join(output_dir, \"processed_calibration_data.npy\")\n",
        "\n",
        "# Process and save each image incrementally to avoid high memory usage\n",
        "with open(calibration_data_path, 'wb') as calib_file, open(processed_data_path, 'wb') as processed_file:\n",
        "    for img_name in os.listdir(image_dir):\n",
        "        img_path = os.path.join(image_dir, img_name)\n",
        "\n",
        "        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            # Resize and normalize the image\n",
        "            img = Image.open(img_path).resize((640, 640))\n",
        "            img_array = np.array(img) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "            # Append the normalized data directly to the file\n",
        "            np.save(calib_file, img_array, allow_pickle=False)\n",
        "            print(f\"Saved {img_name} normalized data to calibration file.\")\n",
        "\n",
        "            # Scale the normalized data back to [0, 255] and save incrementally\n",
        "            processed_calibration_data = img_array * 255.0\n",
        "            np.save(processed_file, processed_calibration_data, allow_pickle=False)\n",
        "            print(f\"Saved {img_name} processed calibration data to file.\")\n",
        "\n",
        "print(\"All images processed and saved.\")"
      ],
      "metadata": {
        "id": "3BM2XJaAdL6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we’re finally ready to optimize it with this script, you can find sample .alls files here, I referenced yolo10nms.json as a base to create my alls file.\n",
        "\n",
        "Note that the change_output_activation applied to my CLS_layer, you can go back and verify this with Netron like specified above.\n",
        "\n"
      ],
      "metadata": {
        "id": "HpQ99d8JMMG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"optimize_model.py\", \"w\") as f:\n",
        "\n",
        "    f.write(\"\"\"\n",
        "\n",
        "import os\n",
        "from hailo_sdk_client import ClientRunner\n",
        "\n",
        "# Define your model's HAR file name\n",
        "model_name = \"best_opset9\"\n",
        "hailo_model_har_name = f\"{model_name}_hailo_model.har\"\n",
        "\n",
        "\n",
        "# Ensure the HAR file exists\n",
        "assert os.path.isfile(f\"{model_name}_hailo_model.har\")\n",
        "\n",
        "# Initialize the ClientRunner with the HAR file\n",
        "runner = ClientRunner(har=hailo_model_har_name)\n",
        "\n",
        "# Define the model script to add a normalization layer\n",
        "# Normalization for [0, 1] range\n",
        "alls = \\\"\\\"\\\"\n",
        "normalization1 = normalization([0.0, 0.0, 0.0], [255.0, 255.0, 255.0])\n",
        "change_output_activation(conv54, sigmoid)\n",
        "change_output_activation(conv65, sigmoid)\n",
        "change_output_activation(conv80, sigmoid)\n",
        "nms_postprocess(\"/content/nms_layer_config.json\", meta_arch=yolov8, engine=cpu)\n",
        "performance_param(compiler_optimization_level=max)\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "# Load the model script into the ClientRunner\n",
        "runner.load_model_script(alls)\n",
        "\n",
        "# Define a calibration dataset\n",
        "# Replace 'calib_dataset' with the actual dataset you're using for calibration\n",
        "# For example, if it's a directory of images, prepare the dataset accordingly\n",
        "calib_dataset = \"/content/output_dir/processed_calibration_data.npy\"\n",
        "\n",
        "# Perform optimization with the calibration dataset\n",
        "runner.optimize(calib_dataset)\n",
        "\n",
        "# Save the optimized model to a new Quantized HAR file\n",
        "quantized_model_har_path = f\"{model_name}_quantized_model.har\"\n",
        "runner.save_har(quantized_model_har_path)\n",
        "\n",
        "print(f\"Quantized HAR file saved to: {quantized_model_har_path}\")\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "8zXSH2RlMHj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!my_env/bin/python optimize_model.py"
      ],
      "metadata": {
        "id": "Kfq92L58MayG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling model"
      ],
      "metadata": {
        "id": "Xqvg9ACHMg6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"optimize_model.py\", \"w\") as f:\n",
        "\n",
        "    f.write(\"\"\"\n",
        "from hailo_sdk_client import ClientRunner\n",
        "\n",
        "# Define the quantized model HAR file\n",
        "model_name = \"best_opset9\"\n",
        "quantized_model_har_path = f\"{model_name}_quantized_model.har\"\n",
        "\n",
        "# Initialize the ClientRunner with the HAR file\n",
        "runner = ClientRunner(har=quantized_model_har_path)\n",
        "print(\"[info] ClientRunner initialized successfully.\")\n",
        "\n",
        "# Compile the model\n",
        "try:\n",
        "    hef = runner.compile()\n",
        "    print(\"[info] Compilation completed successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"[error] Failed to compile the model: {e}\")\n",
        "    raise\n",
        "file_name = f\"{model_name}.hef\"\n",
        "with open(file_name, \"wb\") as f:\n",
        "    f.write(hef)\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "Ay75npCQMjZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!my_env/bin/python compile_model.py"
      ],
      "metadata": {
        "id": "bKKPT3ayM-r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO ZIP"
      ],
      "metadata": {
        "id": "2GczIZpaLcgE"
      }
    }
  ]
}